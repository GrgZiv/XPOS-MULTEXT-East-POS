{"cells":[{"cell_type":"markdown","metadata":{"id":"gDqUG9VUx18v"},"source":["#<h1><center>**Natural Language Processing - XPOS MULTEXT East POS Project**</center></h1>\n","#<h1><center>**2023./2024.**</center></h1>\n","#<h2><center>*Grgur Živković, Mia Mužinić*</center></h1>\n","\n","\n","---\n","\n","\n","#<h1><center>**Model training**</center></h1>"]},{"cell_type":"markdown","metadata":{"id":"XsWgNDH0Mzxi"},"source":["## 1. Loading a preprocessed dataset\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lT1q_ZKqQWPb"},"outputs":[],"source":["# Importing required libraries\n","\n","import ast\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import OneHotEncoder\n","from torch.nn.utils.rnn import pad_sequence"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20824,"status":"ok","timestamp":1708625360287,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"GeOQfx1ANxzi","outputId":"27d58bff-147f-4b4c-eccf-1b6f349791dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":2035,"status":"ok","timestamp":1708625362319,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"k5qloKdIKC_W","outputId":"8c349150-b862-455c-f7ba-fae92f821ce0"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"data_train\",\n  \"rows\": 19791,\n  \"fields\": [\n    {\n      \"column\": \"tokens\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19701,\n        \"samples\": [\n          \"['Sada', ',', 'ka\\u017ee', 'Thompson', ',', 'za', 'tim', 'vi\\u0161e', 'nema', 'potrebe', 'jer', '\\\"', 'ponovno', 'imamo', 'hrvatsku', 'vlast', '\\\"', '.']\",\n          \"['Da', 'nadodam', 'tome', 'da', '10-ak', 'njih', 'kod', 'mene', 've\\u0107', 'godinama', 'ima', 'zasebnu', 'melodiju', 'zvona', ',', 'svatko', 'svoju', ',', 'imam', 'posla', 'sa', 'pode\\u0161avanjem', 'pola', 'sata', 'samo', 'sa', 'kontaktima', '...']\",\n          \"['Policija', 'u', 'jamaj\\u010danskom', 'glavnome', 'gradu', 'Kingstonu', 'objavila', 'je', 'da', 'su', 'provalnici', 'iz', 'ku\\u0107e', 'trostrukog', 'osvaja\\u010da', 'zlatne', 'olimpijske', 'medalje', 'iz', 'Pekinga', 'otu\\u0111ili', '-', '\\u0161to', 'samog', 'novca', '\\u0161to', 'elektroni\\u010dkih', 'aparata', '-', 'u', 'vrijednosti', 'od', '1.000', 'dolara']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"xpos\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19420,\n        \"samples\": [\n          \"['Ncmsn', 'Sg', 'Mdc', 'Y', 'Rgp', 'Px--sa', 'Vmr3s', 'Sg', 'Mdo', 'Ncfsg', 'Z', 'Cc', 'Sg', 'Mdc', 'Y', 'Sl', 'Agpfply', 'Ncfpl', 'Sg', 'Mdo', 'Sg', 'Mdo', 'Ncfsg', 'Z']\",\n          \"['Npfsn', 'Var3s', 'Rgp', 'Vmp-sf', 'Rgp', 'Mlcmsan', 'Agpmsayn', 'Ncmsan', 'Agpmsann', 'Sa', 'Npmsan', 'Sl', 'Npfsl', 'Cc', 'Pd-msn', 'Ncmsn', 'Var3s', 'Agpmsnn', 'Sa', 'Ncmsan', 'Z']\",\n          \"['Npfsn', 'Agpmpgy', 'Ncmpg', 'Vmr3s', 'Vmn', 'Agpmsann', 'Ncmsan', 'Sl', 'Ncfsl', 'Agpfpgy', 'Ncfpg', 'Cc', 'Ncfsl', 'Sg', 'Agpmsgy', 'Ncmsg', 'Cc', 'Ncfsg', 'Z', 'Vmp-sm', 'Var3s', 'Sa', 'Ncmsan', 'Sl', 'Npfsl', 'Agpmsny', 'Ncmsn', 'Npmsg', 'Sa', 'Ncnsa', 'Z']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"data_train"},"text/html":["\n","  <div id=\"df-881a0394-6f9a-4d48-b28c-2174255e78ca\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tokens</th>\n","      <th>xpos</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>['Kazna', 'medijskom', 'mogulu', 'obnovila', '...</td>\n","      <td>['Ncfsn', 'Agpmsdy', 'Ncmsd', 'Vmp-sf', 'Ncfsa...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>['Neki', 'tvrde', 'da', 'je', 'presuda', 'Veli...</td>\n","      <td>['Pi-mpn', 'Vmr3p', 'Cs', 'Var3s', 'Ncfsn', 'N...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>['Medijski', 'mogul', 'Velija', 'Ramkovski', '...</td>\n","      <td>['Agpmsny', 'Ncmsn', 'Npmsn', 'Npmsn', 'Appmsn...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>['Kaznena', 'presuda', 'i', 'zatvorska', 'kazn...</td>\n","      <td>['Agpfsny', 'Ncfsn', 'Cc', 'Agpfsny', 'Ncfsn',...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>['Ramkovski', ',', 'bivši', 'vlasnik', 'televi...</td>\n","      <td>['Npmsn', 'Z', 'Agpmsny', 'Ncmsn', 'Agpfsgy', ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-881a0394-6f9a-4d48-b28c-2174255e78ca')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-881a0394-6f9a-4d48-b28c-2174255e78ca button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-881a0394-6f9a-4d48-b28c-2174255e78ca');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f7c0d56b-1a49-4c47-8d64-ac21f787c0cf\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7c0d56b-1a49-4c47-8d64-ac21f787c0cf')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f7c0d56b-1a49-4c47-8d64-ac21f787c0cf button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"text/plain":["                                              tokens  \\\n","0  ['Kazna', 'medijskom', 'mogulu', 'obnovila', '...   \n","1  ['Neki', 'tvrde', 'da', 'je', 'presuda', 'Veli...   \n","2  ['Medijski', 'mogul', 'Velija', 'Ramkovski', '...   \n","3  ['Kaznena', 'presuda', 'i', 'zatvorska', 'kazn...   \n","4  ['Ramkovski', ',', 'bivši', 'vlasnik', 'televi...   \n","\n","                                                xpos  \n","0  ['Ncfsn', 'Agpmsdy', 'Ncmsd', 'Vmp-sf', 'Ncfsa...  \n","1  ['Pi-mpn', 'Vmr3p', 'Cs', 'Var3s', 'Ncfsn', 'N...  \n","2  ['Agpmsny', 'Ncmsn', 'Npmsn', 'Npmsn', 'Appmsn...  \n","3  ['Agpfsny', 'Ncfsn', 'Cc', 'Agpfsny', 'Ncfsn',...  \n","4  ['Npmsn', 'Z', 'Agpmsny', 'Ncmsn', 'Agpfsgy', ...  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","# Učitavanje pripremljenih podataka\n","file_path_train = '/content/drive/MyDrive/NLP2024/hr500k-train.csv'\n","file_path_val = '/content/drive/MyDrive/NLP2024/hr500k-dev.csv'\n","file_path_test = '/content/drive/MyDrive/NLP2024/hr500k-test.csv'\n","\n","data_train = pd.read_csv(file_path_train)\n","data_val = pd.read_csv(file_path_val)\n","data_test = pd.read_csv(file_path_test)\n","\n","# Prikaz prvih nekoliko redova radi provjere\n","data_train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C1WR4TYNx_zs"},"outputs":[],"source":["# Convert string representations of token sequences to lists of tokens for training data\n","X_train = [ast.literal_eval(sentence) for sentence in data_train['tokens'].tolist()]\n","\n","# Convert string representations of token sequences to lists of tokens for validation data\n","X_valid = [ast.literal_eval(sentence) for sentence in data_val['tokens'].tolist()]\n","\n","# Convert string representations of token sequences to lists of tokens for test data\n","X_test = [ast.literal_eval(sentence) for sentence in data_test['tokens'].tolist()]\n","\n","# Convert string representations of XPOS tag sequences to lists of tags for training data\n","Y_train = [ast.literal_eval(sentence) for sentence in data_train['xpos'].tolist()]\n","\n","# Convert string representations of XPOS tag sequences to lists of tags for validation data\n","Y_valid = [ast.literal_eval(sentence) for sentence in data_val['xpos'].tolist()]\n","\n","# Convert string representations of XPOS tag sequences to lists of tags for test data\n","Y_test = [ast.literal_eval(sentence) for sentence in data_test['xpos'].tolist()]"]},{"cell_type":"markdown","metadata":{"id":"RHVKxVCC7Trr"},"source":["## 2. Dataset class creation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-Z9J4VRPQYFu"},"outputs":[],"source":["# Convert words to integer indices\n","# Initialize an empty dictionary to store word-to-index mappings\n","word_to_idx = {}\n","\n","# Initialize a counter for index values\n","idx_counter = 0\n","\n","# Iterate over the training, validation, and test splits\n","for split in [X_train, X_valid, X_test]:\n","    # Iterate over each sentence in the split\n","    for sentence in split:\n","        # Iterate over each word in the sentence\n","        for word in sentence:\n","            # Check if the word is not already mapped to an index\n","            if word not in word_to_idx:\n","                # Map the word to the current index\n","                word_to_idx[word] = idx_counter\n","                # Increment the index counter\n","                idx_counter += 1\n","\n","# Initialize an empty dictionary to store XPOS tag-to-index mappings\n","xpos_to_idx = {}\n","\n","# Re-initialize the counter for index values\n","idx_counter = 0\n","\n","# Iterate over the training, validation, and test splits for XPOS tags\n","for tag_split in [Y_train, Y_valid, Y_test]:\n","    # Iterate over each list of XPOS tags\n","    for tags in tag_split:\n","        # Iterate over each XPOS tag in the list\n","        for tag in tags:\n","            # Check if the XPOS tag is not already mapped to an index\n","            if tag not in xpos_to_idx:\n","                # Map the XPOS tag to the current index\n","                xpos_to_idx[tag] = idx_counter\n","                # Increment the index counter\n","                idx_counter += 1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1708625364690,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"6wiVrcEc8XjO","outputId":"87d556ca-81d5-485e-bfe9-fd7a4078d5a5"},"outputs":[{"data":{"text/plain":["73456"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# Number of unique words\n","len(word_to_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1708625364690,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"g0fgp4Le8cjG","outputId":"7db5ea57-be05-40ea-c110-c447e8a5ddf6"},"outputs":[{"data":{"text/plain":["756"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["# Number of unique xpos tags\n","len(xpos_to_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1708625364690,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"Ho2LbuGTQaKG","outputId":"b1d780e4-9799-4aae-f1ce-f1fe075d36e4"},"outputs":[{"data":{"text/plain":["{'Kazna': 0,\n"," 'medijskom': 1,\n"," 'mogulu': 2,\n"," 'obnovila': 3,\n"," 'raspravu': 4,\n"," 'u': 5,\n"," 'Makedoniji': 6,\n"," 'Neki': 7,\n"," 'tvrde': 8,\n"," 'da': 9,\n"," 'je': 10}"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["# Sanity check\n","dict(list(word_to_idx.items())[:11])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1708625364691,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"KtuLFtdyURd4","outputId":"7c9af1a9-68b3-405e-d9ad-ae54673e709b"},"outputs":[{"data":{"text/plain":["{'Ncfsn': 0,\n"," 'Agpmsdy': 1,\n"," 'Ncmsd': 2,\n"," 'Vmp-sf': 3,\n"," 'Ncfsa': 4,\n"," 'Sl': 5,\n"," 'Npfsl': 6,\n"," 'Pi-mpn': 7,\n"," 'Vmr3p': 8,\n"," 'Cs': 9,\n"," 'Var3s': 10}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# Sanity check\n","dict(list(pos_to_idx.items())[:11])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20,"status":"ok","timestamp":1708625364691,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"K_M_lQGn80Ed","outputId":"a4d81ad3-f231-4f54-b21b-49bb6349dde1"},"outputs":[{"data":{"text/plain":["19791"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["len(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1708625364691,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"-XWbAmBr83EI","outputId":"3f66e86c-5d92-43e9-e1d8-474de13778e0"},"outputs":[{"data":{"text/plain":["2486"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["len(X_valid)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1708625364692,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"HhwV-E9y8paR","outputId":"f2ab558a-93cb-4df1-8a54-ed92f9c253b4"},"outputs":[{"data":{"text/plain":["22277"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["# Number of Train + Test data points\n","len((X_train+X_valid))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OmG86nauUuzs"},"outputs":[],"source":["# Define a PyTorch Dataset\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, sentences, xpos_tags, word_to_idx, xpos_to_idx):\n","        \"\"\"\n","        Initializes the CustomDataset.\n","\n","        Args:\n","        - sentences (list): List of sentences, where each sentence is represented as a list of words.\n","        - xpos_tags (list): List of XPOS tag sequences, where each sequence is represented as a list of tags.\n","        - word_to_idx (dict): Dictionary mapping words to their corresponding indices.\n","        - xpos_to_idx (dict): Dictionary mapping XPOS tags to their corresponding indices.\n","        \"\"\"\n","        self.sentences = sentences   # Store the list of sentences\n","        self.xpos_tags = xpos_tags   # Store the list of XPOS tag sequences\n","        self.word_to_idx = word_to_idx  # Store the word-to-index mapping\n","        self.xpos_to_idx = xpos_to_idx    # Store the XPOS tag-to-index mapping\n","\n","    def __len__(self):\n","        \"\"\"\n","        Returns the total number of sentences in the dataset.\n","        \"\"\"\n","        return len(self.sentences)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Retrieves a sample from the dataset at the specified index.\n","\n","        Args:\n","        - idx (int): Index of the sample to retrieve.\n","\n","        Returns:\n","        - word_indices (list): List of integer indices representing words in the sentence.\n","        - xpos_indices (list): List of integer indices representing XPOS tags in the sentence.\n","        \"\"\"\n","        # Retrieve the list of word indices for the sentence at the given index\n","        word_indices = [self.word_to_idx[word] for word in self.sentences[idx]]\n","        # Retrieve the list of XPOS tag indices for the sentence at the given index\n","        xpos_indices = [self.xpos_to_idx[tag] for tag in self.xpos_tags[idx]]\n","        # Return the word indices and XPOS tag indices as a tuple\n","        return word_indices, xpos_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F7EA2sinU3AA"},"outputs":[],"source":["# Create the dataset\n","dataset_train = CustomDataset(X_train, Y_train, word_to_idx, xpos_to_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCbQBbRo_E_C"},"outputs":[],"source":["dataset_val = CustomDataset(X_valid, Y_valid, word_to_idx, xpos_to_idx)"]},{"cell_type":"markdown","metadata":{"id":"r-v8-1ul7e5k"},"source":["## 3. Embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eeuL7bsZSuiY"},"outputs":[],"source":["def collate_fn(batch):\n","    # Separate word indices and XPOS tag indices\n","    word_indices, xpos_indices = zip(*batch)\n","\n","    # Pad sequences to the same length within each batch\n","    # Convert each sequence of word indices to a PyTorch tensor and pad them\n","    padded_word_indices = pad_sequence([torch.tensor(seq) for seq in word_indices], batch_first=True)\n","    # Convert each sequence of XPOS tag indices to a PyTorch tensor and pad them\n","    padded_xpos_indices = pad_sequence([torch.tensor(seq) for seq in xpos_indices], batch_first=True)\n","\n","    # Return padded sequences of word indices and XPOS tag indices\n","    return padded_word_indices, padded_xpos_indices"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MXGQeMePVc2l"},"outputs":[],"source":["# Create DataLoader\n","\n","# Define the batch size\n","batch_size = 32\n","\n","# Create a DataLoader for the training dataset\n","dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","\n","# Create a DataLoader for the validation dataset\n","dataloader_val = DataLoader(dataset_val, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)"]},{"cell_type":"markdown","metadata":{"id":"8BKXdxPPM-sH"},"source":["## 4. Model building"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DxzYEBz57oei"},"outputs":[],"source":["# Define the RNN model\n","class RNNClassifier(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):\n","        \"\"\"\n","        Initializes the RNNClassifier module.\n","\n","        Args:\n","        - input_size (int): Size of the input vocabulary.\n","        - hidden_size (int): Size of the hidden state of the RNN.\n","        - output_size (int): Size of the output (number of classes).\n","        \"\"\"\n","        super(RNNClassifier, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.embedding = nn.Embedding(input_size, embedding_dim)\n","        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n","        self.fc = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Forward pass of the RNNClassifier module.\n","\n","        Args:\n","        - x (Tensor): Input tensor representing input sequences.\n","\n","        Returns:\n","        - output (Tensor): Output tensor representing the class predictions.\n","        \"\"\"\n","        # Embed the input sequences\n","        embedded = self.embedding(x)\n","        # Pass the embedded sequences through the RNN layer\n","        output, hidden = self.rnn(embedded)\n","        # Pass the RNN output through the fully connected layer\n","        output = self.fc(output)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"spEZ5W2a8KSt"},"outputs":[],"source":["# Define hyperparameters\n","vocab_size = len(word_to_idx)\n","embedding_dim = 100\n","num_pos_tags = len(xpos_to_idx)\n","\n","input_size = vocab_size\n","hidden_size = 128\n","output_size = len(xpos_to_idx)\n","\n","# For GPU usage\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# Create the RNN model\n","rnn_model = RNNClassifier(input_size, hidden_size, output_size).to(device)"]},{"cell_type":"markdown","metadata":{"id":"6eCU13GF8mmK"},"source":["## 5. Model training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q95iM-hc8paT"},"outputs":[],"source":["# Define loss function and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":37422,"status":"ok","timestamp":1708626601007,"user":{"displayName":"Grgur Živković","userId":"14552076762889595041"},"user_tz":-60},"id":"PL7FLrX7_9pZ","outputId":"1e2fc8b3-e2fd-406a-c8e6-8bdccfcb31e2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10, Training Loss: 0.1908, Training Accuracy: 0.9628\n","Epoch 1/10, Validation Accuracy: 0.9103\n","Epoch 2/10, Training Loss: 0.1497, Training Accuracy: 0.9688\n","Epoch 2/10, Validation Accuracy: 0.9126\n","Epoch 3/10, Training Loss: 0.1346, Training Accuracy: 0.9740\n","Epoch 3/10, Validation Accuracy: 0.9142\n","Epoch 4/10, Training Loss: 0.1065, Training Accuracy: 0.9786\n","Epoch 4/10, Validation Accuracy: 0.9123\n","Epoch 5/10, Training Loss: 0.0966, Training Accuracy: 0.9823\n","Epoch 5/10, Validation Accuracy: 0.9155\n","Epoch 6/10, Training Loss: 0.0670, Training Accuracy: 0.9853\n","Epoch 6/10, Validation Accuracy: 0.9138\n","Epoch 7/10, Training Loss: 0.0280, Training Accuracy: 0.9881\n","Epoch 7/10, Validation Accuracy: 0.9147\n","Epoch 8/10, Training Loss: 0.0248, Training Accuracy: 0.9902\n","Epoch 8/10, Validation Accuracy: 0.9146\n","Epoch 9/10, Training Loss: 0.0333, Training Accuracy: 0.9918\n","Epoch 9/10, Validation Accuracy: 0.9126\n","Epoch 10/10, Training Loss: 0.0242, Training Accuracy: 0.9933\n","Epoch 10/10, Validation Accuracy: 0.9128\n"]}],"source":["# Define the number of epochs\n","num_epochs = 10\n","\n","# Training loop\n","for epoch in range(num_epochs):\n","    # Set the model to train mode\n","    rnn_model.train()\n","\n","    # Initialize variables to track training loss and accuracy\n","    correct_train = 0\n","    total_train = 0\n","\n","    # Iterate over the training dataset\n","    for inputs, targets in dataloader_train:\n","        # Move inputs and targets to the device\n","        inputs, targets = inputs.to(device), targets.to(device)\n","\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        outputs = rnn_model(inputs)\n","\n","        # Calculate the loss\n","        loss = criterion(outputs.view(-1, output_size), targets.view(-1))\n","\n","        # Backward pass\n","        loss.backward()\n","\n","        # Update the parameters\n","        optimizer.step()\n","\n","\n","        # Calculate the number of correctly predicted samples\n","        _, predicted = torch.max(outputs, 2)\n","        correct_train += (predicted == targets).sum().item()\n","        total_train += targets.numel()\n","\n","    # Calculate training accuracy\n","    train_accuracy = correct_train / total_train\n","\n","    # Print training loss and accuracy for the current epoch\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {loss.item():.4f}, Training Accuracy: {train_accuracy:.4f}\")\n","\n","    # Validation loop\n","    rnn_model.eval()  # Set the model to evaluation mode\n","    correct_val = 0\n","    total_val = 0\n","\n","    # Disable gradient calculation to save memory and computation\n","    with torch.no_grad():\n","        for val_inputs, val_targets in dataloader_val:\n","            val_inputs, val_targets = val_inputs.to(device), val_targets.to(device)\n","            val_outputs = rnn_model(val_inputs)\n","            _, val_predicted = torch.max(val_outputs, 2)\n","            correct_val += (val_predicted == val_targets).sum().item()\n","            total_val += val_targets.numel()\n","\n","    # Calculate validation accuracy\n","    val_accuracy = correct_val / total_val\n","\n","    # Print validation accuracy for the current epoch\n","    print(f\"Epoch {epoch+1}/{num_epochs}, Validation Accuracy: {val_accuracy:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5evrPFfRR27E"},"outputs":[],"source":["# Saving the model along with state\n","torch.save(rnn_model, '/content/drive/MyDrive/NLP2024/entire_rnn_model.h5')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1m9cEnEIGMOtb-l9w-qplAdCBCUZLj_xn","timestamp":1708010195889}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
